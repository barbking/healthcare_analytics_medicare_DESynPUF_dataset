{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment for Graduate Course in Healthcare Analytics\n",
    "- Using DE-SynPUF files downloaded from https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DE_Syn_PUF.html\n",
    "- Assignment: use methods related to decision trees to predict depression as response/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and read file, use NaN for elements with no values\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"combined_ben_sum_AddYear.csv\", na_values = ['no info', '.'])\n",
    "#print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of data needed to answer assignment question #4\n",
    "newdf = df[['DESYNPUF_ID','Year','BENE_BIRTH_DT','BENE_SEX_IDENT_CD','BENE_RACE_CD',\n",
    "            'BENE_ESRD_IND','SP_STATE_CODE','BENE_COUNTY_CD','SP_ALZHDMTA',\n",
    "       'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD','SP_DEPRESSN',\n",
    "       'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA']]\n",
    "#print(newdf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see how many duplicate rows, all columns except year\n",
    "# don't want to skew results if have same patient over 2008-2010 with same conditions repeated each year\n",
    "# only want to include if patient has developed new conditions\n",
    "dup_df = newdf[newdf.duplicated(['DESYNPUF_ID','BENE_BIRTH_DT','BENE_SEX_IDENT_CD','BENE_RACE_CD',\n",
    "                'BENE_ESRD_IND','SP_STATE_CODE','BENE_COUNTY_CD','SP_ALZHDMTA',\n",
    "                'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD','SP_DEPRESSN',\n",
    "                'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA']) == True].sort_values(by='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(dup_df)\n",
    "dup_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicate rows, 1424410 removed\n",
    "df_no_dup_records_1 = newdf.drop_duplicates(['DESYNPUF_ID','BENE_BIRTH_DT','BENE_SEX_IDENT_CD','BENE_RACE_CD',\n",
    "            'BENE_ESRD_IND','SP_STATE_CODE','BENE_COUNTY_CD','SP_ALZHDMTA',\n",
    "       'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD','SP_DEPRESSN',\n",
    "       'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_dup_records_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also remove all recorcds after patient's first diagnosis, any future conditions post-depression diagnosis would not be a \n",
    "# predictor or cause of depression\n",
    "df_no_dup_records = df_no_dup_records_1.drop_duplicates(['DESYNPUF_ID','BENE_BIRTH_DT','SP_DEPRESSN'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2,291,711â€¬ rows removed\n",
    "df_no_dup_records.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate age (year column - year from BENE_BIRTH_DT)\n",
    "#newdf[\"Birth_Year\"] = pd.to_datetime(newdf['BENE_BIRTH_DT']).dt.year\n",
    "df_no_dup_records.loc[:,'Age'] = df_no_dup_records.loc[:,'Year'] - (pd.to_datetime(newdf.loc[:,'BENE_BIRTH_DT'],format='%Y%m%d').dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display and check age calculation working as expected\n",
    "display(df_no_dup_records.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for any patients with multiple recods in one year (should only have one patient summary per year)\n",
    "df_dup_record_year = df_no_dup_records[df_no_dup_records.duplicated(['DESYNPUF_ID','Year']) == True].sort_values(by='DESYNPUF_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup_record_year.shape\n",
    "# returned 0 rows so we don't have any rows with duplicate patient ID and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_no_dup_records.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the chronic condition col, prev data was 2 = no and 1 = yes\n",
    "# replace 2 with 0 so have 0 = no and 1 = yes\n",
    "for column in range(8,19):\n",
    "    df_no_dup_records.iloc[:,column] = df_no_dup_records.iloc[:,column].replace(2,0)\n",
    "    \n",
    "# for BENE_ESRD_IND replace 'Y' with 1, 'N' is already set to 0\n",
    "df_no_dup_records.loc[:,'BENE_ESRD_IND'] = df_no_dup_records.loc[:,'BENE_ESRD_IND'].replace('Y',1)\n",
    "\n",
    "# enocde race column\n",
    "df_no_dup_records.loc[:,'BENE_RACE_CD'] = df_no_dup_records.loc[:,'BENE_RACE_CD'].replace({1:'White',2:'Black',3:'Other', 5:'Hispanic'}).apply(str)\n",
    "#Binary Encoding Catergorical Variables without Order\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['BENE_RACE_CD'])\n",
    "df_no_dup_records = encoder.fit_transform(df_no_dup_records)\n",
    "\n",
    "# set sex to male = 0 and female = 1\n",
    "df_no_dup_records.loc[:,'BENE_SEX_IDENT_CD'] = df_no_dup_records.loc[:,'BENE_SEX_IDENT_CD'].replace({1:0,2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying values look good\n",
    "display(df_no_dup_records.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model with Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_no_dup_records.loc[:,['BENE_SEX_IDENT_CD',\n",
    "       'BENE_RACE_CD_0', 'BENE_RACE_CD_1', 'BENE_RACE_CD_2', 'BENE_ESRD_IND','SP_ALZHDMTA', 'SP_CHF',\n",
    "       'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD', 'SP_DIABETES',\n",
    "       'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA', 'Age']].values\n",
    "y = df_no_dup_records.loc[:,'SP_DEPRESSN'].values\n",
    "\n",
    "#Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifierObj = RandomForestClassifier(n_estimators=10, criterion='gini', bootstrap=False)\n",
    "classifierObj.fit(X_train,y_train)\n",
    "#grid_param= {  \n",
    "#    'n_estimators': [5, 10, 15],\n",
    "#    'criterion': ['gini', 'entropy'],\n",
    "#    'bootstrap': [True, False]\n",
    "#}\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#gd_sr= GridSearchCV(estimator=classifierObj, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#gd_sr.fit(X_train, y_train) \n",
    "#print(gd_sr.best_params_) \n",
    "#print(gd_sr.best_score_)\n",
    "# grid search results {'bootstrap': False, 'criterion': 'gini', 'n_estimators': 10} score: 0.682652136395948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#modelAccuracies = cross_val_score(estimator=classifierObj, X=X_train, y=y_train, cv=10)\n",
    "#print(modelAccuracies.mean())\n",
    "#print(modelAccuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('recall: {0:0.2f}'.format(recall))\n",
    "print('precision: {0:0.2f}'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "# predict probabilities\n",
    "lr_probs = classifierObj.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = classifierObj.predict(X_test)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('RandomForest: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='DecisionTree')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with Balanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df_no_dup_records.SP_DEPRESSN.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df_no_dup_records[df_no_dup_records['SP_DEPRESSN'] == 0]\n",
    "df_class_1 = df_no_dup_records[df_no_dup_records['SP_DEPRESSN'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.SP_DEPRESSN.value_counts())\n",
    "\n",
    "df_test_under.SP_DEPRESSN.value_counts().plot(kind='bar', title='Count (SP_DEPRESSN)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_under.columns)\n",
    "print(df_test_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test\n",
    "X_bal = df_test_under.loc[:,['BENE_SEX_IDENT_CD',\n",
    "       'BENE_RACE_CD_0', 'BENE_RACE_CD_1', 'BENE_RACE_CD_2', 'BENE_ESRD_IND','SP_ALZHDMTA', 'SP_CHF',\n",
    "       'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD', 'SP_DIABETES',\n",
    "       'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA', 'Age']].values\n",
    "y_bal = df_test_under.loc[:,'SP_DEPRESSN'].values\n",
    "\n",
    "#Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_bal,y_bal,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifierObj2 = RandomForestClassifier(n_estimators=10, criterion='gini', bootstrap=False)\n",
    "classifierObj2.fit(X_train,y_train)\n",
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "modelAccuracies = cross_val_score(estimator=classifierObj2, X=X_train, y=y_train, cv=10)\n",
    "print(modelAccuracies.mean())\n",
    "print(modelAccuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj2.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('recall: {0:0.2f}'.format(recall))\n",
    "print('precision: {0:0.2f}'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "# predict probabilities\n",
    "lr_probs = classifierObj2.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = classifierObj2.predict(X_test)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('RandomForest: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='RandomForest')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
